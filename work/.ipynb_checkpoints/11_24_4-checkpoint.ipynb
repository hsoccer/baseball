{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "#plt.style.use('seaborn-pastel')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm_notebook as tq\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils.util_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流れがいい時だけ取り出して得点の分散との関係を見る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_improved(before, after):\n",
    "    if before[0] == after[0]:\n",
    "        if int(before[::-1][:-1]) <= int(after[::-1][:-1]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_deteriorated(before, after):\n",
    "    if int(before[0]) < int(after):\n",
    "        if int(before[::-1][:-1]) >= int(after[::-1][:-1]):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "    [\"0000\", \"1000\", True],\n",
    "    [\"0000\", \"0100\", False],\n",
    "    [\"1100\", \"2010\", False],\n",
    "    [\"1100\", \"1110\", False],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for [before, after, res] in test:\n",
    "    if is_deteriorated(before, after) == res:\n",
    "        pass\n",
    "    else:\n",
    "        print([before, after, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = make_df(\"20180101\", \"20181231\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = \"ロッテ\"\n",
    "lst = make_flattened_list(make_inning_triple(make_inning_list(event_df[event_df.攻撃チーム==team])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_lst = [elem for elem in lst if is_improved(elem[0], elem[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(improved_lst), len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cond_entropy = cond_entropy(pd.DataFrame(improved_lst)[2].values, pd.DataFrame(improved_lst)[[0, 1]].values)\n",
    "first_cond_entropy = cond_entropy(pd.DataFrame(improved_lst)[2].values, pd.DataFrame(improved_lst)[[1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cond_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cond_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"得点\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "stds = []\n",
    "for team in pacific+central:\n",
    "    lst = make_flattened_list(make_inning_triple(make_inning_list(event_df[event_df.攻撃チーム==team])))\n",
    "    #improved_lst = [elem for elem in lst if is_improved(elem[0], elem[1])]\n",
    "    improved_lst = [elem for elem in lst if is_deteriorated(elem[0], elem[1])]\n",
    "    # H(St+1 | St, St-1)\n",
    "    second_cond_entropy = cond_entropy(pd.DataFrame(improved_lst)[2].values, pd.DataFrame(improved_lst)[[0, 1]].values)\n",
    "    # H(St+1 | St)\n",
    "    first_cond_entropy = cond_entropy(pd.DataFrame(improved_lst)[2].values, pd.DataFrame(improved_lst)[[1]].values)\n",
    "    std = make_score_df(team).describe()[column][\"std\"] #/ make_score_df(team).describe()[column][\"mean\"]\n",
    "    diffs.append(second_cond_entropy - first_cond_entropy)\n",
    "    stds.append(std)\n",
    "    print(team, second_cond_entropy - first_cond_entropy, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diffs[:6], stds[:6], color=\"red\")\n",
    "plt.scatter(diffs[6:], stds[6:], color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "nsample = len(diffs)\n",
    "X = np.column_stack((np.repeat(1, nsample), diffs))\n",
    "\n",
    "model = sm.OLS(stds, X)\n",
    "results = model.fit()\n",
    "\n",
    "a, b = results.params\n",
    "\n",
    "plt.scatter(diffs, stds)\n",
    "plt.plot(diffs, a+b*np.array(diffs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(DETAIL_DATA_DIR_MLB)[1:]\n",
    "res = []\n",
    "for file in files:\n",
    "    res.append(pd.read_csv(os.path.join(DETAIL_DATA_DIR_MLB, file), encoding=\"cp932\", dtype=str).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inning_list = []\n",
    "for elem in res:\n",
    "    try:\n",
    "        inning_list.append(np.array(elem)[:, 1].tolist() + [\"GAMESET\"])\n",
    "    except:\n",
    "        print(\"ng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_df = make_df(data_dir=DETAIL_DATA_DIR_MLB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"得点\"\n",
    "teams_mlb = list(set(pd.read_csv(os.path.join(SCORE_DATA_DIR_MLB, \"score_mlb.csv\"), encoding=\"cp932\", index_col=0).表チーム))\n",
    "teams_mlb.remove(\"ア・リーグ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_df_mlb(team, year=\"both\"):\n",
    "    num = 1944417\n",
    "    res = []\n",
    "    columns = [\"相手\", \"得点\", \"失点\"]\n",
    "    df = pd.read_csv(os.path.join(SCORE_DATA_DIR_MLB, \"score_mlb.csv\"), encoding=\"cp932\", index_col=0)\n",
    "    if year == \"both\":\n",
    "        df_top = df[df[\"表チーム\"]==team]\n",
    "        df_bot = df[df[\"裏チーム\"]==team]\n",
    "    elif int(year) == 2018:\n",
    "        df_top = df[(df[\"表チーム\"]==team) & (df[\"試合ID\"].apply(lambda x: int(x.split(\".\")[0]))>num)]\n",
    "        df_bot = df[(df[\"裏チーム\"]==team) & (df[\"試合ID\"].apply(lambda x: int(x.split(\".\")[0]))>num)]\n",
    "    elif int(year) == 2017:\n",
    "        df_top = df[(df[\"表チーム\"]==team) & (df[\"試合ID\"].apply(lambda x: int(x.split(\".\")[0]))<=num)]\n",
    "        df_bot = df[(df[\"裏チーム\"]==team) & (df[\"試合ID\"].apply(lambda x: int(x.split(\".\")[0]))<=num)]\n",
    "    for elem in df_top.values:\n",
    "        res.append([elem[2], elem[3], elem[4]])\n",
    "    for elem in df_bot.values:\n",
    "        res.append([elem[1], elem[4], elem[3]])\n",
    "    return pd.DataFrame(res, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_score_df_mlb(\"Rソックス\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "stds = []\n",
    "for team in teams_mlb:\n",
    "    lst = make_flattened_list(make_inning_triple(make_inning_list(event_df[event_df.攻撃チーム==team])))\n",
    "    improved_lst = [elem for elem in lst if is_deteriorated(elem[0], elem[1])]\n",
    "    # H(St+1 | St, St-1)\n",
    "    second_cond_entropy = cond_entropy(pd.DataFrame(improved_lst)[2].values, pd.DataFrame(improved_lst)[[0, 1]].values)\n",
    "    # H(St+1 | St)\n",
    "    first_cond_entropy = cond_entropy(pd.DataFrame(improved_lst)[2].values, pd.DataFrame(improved_lst)[[1]].values)\n",
    "    std = make_score_df_mlb(team).describe()[column][\"std\"] #/ make_score_df_mlb(team).describe()[column][\"mean\"]\n",
    "    diffs.append(second_cond_entropy - first_cond_entropy)\n",
    "    stds.append(std)\n",
    "    print(team, second_cond_entropy - first_cond_entropy, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diffs, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "nsample = len(diffs)\n",
    "X = np.column_stack((np.repeat(1, nsample), diffs))\n",
    "\n",
    "model = sm.OLS(stds, X)\n",
    "results = model.fit()\n",
    "\n",
    "a, b = results.params\n",
    "\n",
    "plt.scatter(diffs, stds)\n",
    "plt.plot(diffs, a+b*np.array(diffs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([(1, 2, 3), (4, 5, 6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_proba(target, lst):\n",
    "    if type(lst) == np.ndarray:\n",
    "        lst = lst.tolist()\n",
    "    return lst.count(target) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_proba([1, 2, 2], np.array([[1, 2, 3], [5, 6, 7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(triple_list):\n",
    "    triple_proba_dict = pd.Series(lst).value_counts() / len(lst)\n",
    "    double_form_proba_dict = pd.Series(np.array(lst)[:, [0, 1]].tolist()).apply(lambda x: tuple(x)).value_counts() / len(lst)\n",
    "    double_late_proba_dict = pd.Series(np.array(lst)[:, [1, 2]].tolist()).apply(lambda x: tuple(x)).value_counts() / len(lst)\n",
    "    single_form_proba_dict = pd.Series(np.array(lst)[:, 0]).value_counts() / len(lst)\n",
    "    single_curr_proba_dict = pd.Series(np.array(lst)[:, 1]).value_counts() / len(lst)\n",
    "    single_late_proba_dict = pd.Series(np.array(lst)[:, 2]).value_counts() / len(lst)\n",
    "    \n",
    "    EPSILON = 1e-9\n",
    "    triple_array = np.array(triple_list)\n",
    "    forms = triple_array[:, 0]\n",
    "    currs = triple_array[:, 1]\n",
    "    lates = triple_array[:, 2]\n",
    "    \n",
    "    res = 0\n",
    "    for form in set(forms):\n",
    "        proba = single_form_proba_dict[form]\n",
    "        for curr in set(currs):\n",
    "            for late in set(lates):\n",
    "                try:\n",
    "                    second_joint = triple_proba_dict[(form, curr, late)]\n",
    "                except:\n",
    "                    second_joint = 0\n",
    "                try:\n",
    "                    second_cond = double_form_proba_dict[(form, curr)]\n",
    "                except:\n",
    "                    second_cond = 0\n",
    "                try:\n",
    "                    first_joint = double_late_proba_dict[(curr, late)]\n",
    "                except:\n",
    "                    first_joint = 0\n",
    "                try:\n",
    "                    first_cond = single_curr_proba_dict[curr]\n",
    "                except:\n",
    "                    first_cond = 0\n",
    "                second_cond_proba = second_joint / (second_cond+EPSILON)\n",
    "                first_cond_proba = first_joint / (first_cond+EPSILON)\n",
    "                res += proba * (second_cond_proba*np.log(second_cond_proba+EPSILON) - first_cond_proba*np.log(first_cond_proba+EPSILON))\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calc_entropy(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"triple_proba_dict = pd.Series(lst).value_counts() / len(lst)\n",
    "double_form_proba_dict = pd.Series(np.array(lst)[:, [0, 1]].tolist()).apply(lambda x: tuple(x)).value_counts() / len(lst)\n",
    "double_late_proba_dict = pd.Series(np.array(lst)[:, [1, 2]].tolist()).apply(lambda x: tuple(x)).value_counts() / len(lst)\n",
    "single_form_proba_dict = pd.Series(np.array(lst)[:, 0]).value_counts() / len(lst)\n",
    "single_curr_proba_dict = pd.Series(np.array(lst)[:, 1]).value_counts() / len(lst)\n",
    "single_late_proba_dict = pd.Series(np.array(lst)[:, 2]).value_counts() / len(lst)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "stds = []\n",
    "for team in pacific+central:\n",
    "    lst = make_flattened_list(make_inning_triple(make_inning_list(event_df[event_df.攻撃チーム==team])))\n",
    "    std = make_score_df(team).describe()[column][\"std\"] / make_score_df(team).describe()[column][\"mean\"]\n",
    "    diffs.append(calc_entropy(lst))\n",
    "    stds.append(std)\n",
    "    print(team, diffs[-1], std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diffs[:6], stds[:6], color=\"red\")\n",
    "plt.scatter(diffs[6:], stds[6:], color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "nsample = len(diffs)\n",
    "X = np.column_stack((np.repeat(1, nsample), diffs))\n",
    "\n",
    "model = sm.OLS(stds, X)\n",
    "results = model.fit()\n",
    "\n",
    "a, b = results.params\n",
    "\n",
    "plt.scatter(diffs, stds)\n",
    "plt.plot(diffs, a+b*np.array(diffs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "stds = []\n",
    "for team in teams_mlb:\n",
    "    lst = make_flattened_list(make_inning_triple(make_inning_list(event_df[event_df.攻撃チーム==team])))\n",
    "    std = make_score_df_mlb(team).describe()[column][\"std\"] #/ make_score_df_mlb(team).describe()[column][\"mean\"]\n",
    "    second_cond_entropy = cond_entropy(pd.DataFrame(lst)[2].values, pd.DataFrame(lst)[[0, 1]].values)\n",
    "    first_cond_entropy = cond_entropy(pd.DataFrame(lst)[2].values, pd.DataFrame(lst)[[1]].values)\n",
    "    #diffs.append(calc_entropy(lst))\n",
    "    diffs.append(first_cond_entropy-second_cond_entropy)\n",
    "    stds.append(std)\n",
    "    print(team, diffs[-1], std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "nsample = len(diffs)\n",
    "X = np.column_stack((np.repeat(1, nsample), diffs))\n",
    "\n",
    "model = sm.OLS(stds, X)\n",
    "results = model.fit()\n",
    "\n",
    "a, b = results.params\n",
    "\n",
    "plt.scatter(diffs, stds)\n",
    "plt.plot(diffs, a+b*np.array(diffs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "stds = []\n",
    "for team in teams_mlb:\n",
    "    lst = make_flattened_list(make_inning_triple(make_inning_list(event_df[event_df.攻撃チーム==team])))\n",
    "    std = make_score_df_mlb(team).describe()[column][\"std\"] #/ make_score_df_mlb(team).describe()[column][\"mean\"]\n",
    "    diffs.append(calc_entropy(lst))\n",
    "    stds.append(std)\n",
    "    print(team, diffs[-1], std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "nsample = len(diffs)\n",
    "X = np.column_stack((np.repeat(1, nsample), diffs))\n",
    "\n",
    "model = sm.OLS(stds, X)\n",
    "results = model.fit()\n",
    "\n",
    "a, b = results.params\n",
    "\n",
    "plt.scatter(diffs, stds)\n",
    "plt.plot(diffs, a+b*np.array(diffs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = make_df(data_dir=DETAIL_DATA_DIR_MLB)\n",
    "df_2017 = make_df(end=1944417, data_dir=DETAIL_DATA_DIR_MLB)\n",
    "df_2018 = make_df(start=1944417, data_dir=DETAIL_DATA_DIR_MLB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(DETAIL_DATA_DIR_MLB)[1:]\n",
    "names = pd.Series(files).apply(lambda x: int(x.split(\".\")[0]))\n",
    "files_2017 = names[names<=1944417].apply(lambda x: str(x)+\".csv\")\n",
    "files_2018 = names[names>1944417].apply(lambda x: str(x)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"得点\"\n",
    "teams_mlb = list(set(pd.read_csv(os.path.join(SCORE_DATA_DIR_MLB, \"score_mlb.csv\"), encoding=\"cp932\", index_col=0).表チーム))\n",
    "teams_mlb.remove(\"ア・リーグ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "stds = []\n",
    "for team in teams_mlb:\n",
    "    lst_2017 = make_flattened_list(make_inning_triple(make_inning_list(df_2017[df_2017.攻撃チーム==team])))\n",
    "    #lst_2018 = make_flattened_list(make_inning_triple(make_inning_list(df_2018[df_2018.攻撃チーム==team])))\n",
    "    std_2017 = make_score_df_mlb(team, 2017).describe()[column][\"std\"] / make_score_df_mlb(team, 2017).describe()[column][\"mean\"]\n",
    "    #std_2018 = make_score_df_mlb(team, 2018).describe()[column][\"std\"] / make_score_df_mlb(team, 2018).describe()[column][\"mean\"]\n",
    "    second_cond_entropy_2017 = cond_entropy(pd.DataFrame(lst_2017)[2].values, pd.DataFrame(lst_2017)[[0, 1]].values)\n",
    "    first_cond_entropy_2017 = cond_entropy(pd.DataFrame(lst_2017)[2].values, pd.DataFrame(lst_2017)[[1]].values)\n",
    "    #second_cond_entropy_2018 = cond_entropy(pd.DataFrame(lst_2018)[2].values, pd.DataFrame(lst_2018)[[0, 1]].values)\n",
    "    #first_cond_entropy_2018 = cond_entropy(pd.DataFrame(lst_2018)[2].values, pd.DataFrame(lst_2018)[[1]].values)\n",
    "    diffs.append(first_cond_entropy_2017-second_cond_entropy_2017)\n",
    "    stds.append(std_2017)\n",
    "    #diffs.append(first_cond_entropy_2018-second_cond_entropy_2018)\n",
    "    #stds.append(std_2018)\n",
    "    print(team, diffs[-1], std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "nsample = len(diffs)\n",
    "X = np.column_stack((np.repeat(1, nsample), diffs))\n",
    "\n",
    "model = sm.OLS(stds, X)\n",
    "results = model.fit()\n",
    "\n",
    "a, b = results.params\n",
    "\n",
    "plt.scatter(diffs, stds)\n",
    "plt.plot(diffs, a+b*np.array(diffs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "stds = []\n",
    "for team in teams_mlb:\n",
    "    #lst_2017 = make_flattened_list(make_inning_triple(make_inning_list(df_2017[df_2017.攻撃チーム==team])))\n",
    "    lst_2018 = make_flattened_list(make_inning_triple(make_inning_list(df_2018[df_2018.攻撃チーム==team])))\n",
    "    #std_2017 = make_score_df_mlb(team, 2017).describe()[column][\"std\"] / make_score_df_mlb(team, 2017).describe()[column][\"mean\"]\n",
    "    std_2018 = make_score_df_mlb(team, 2018).describe()[column][\"std\"] / make_score_df_mlb(team, 2018).describe()[column][\"mean\"]\n",
    "    #second_cond_entropy_2017 = cond_entropy(pd.DataFrame(lst_2017)[2].values, pd.DataFrame(lst_2017)[[0, 1]].values)\n",
    "    #first_cond_entropy_2017 = cond_entropy(pd.DataFrame(lst_2017)[2].values, pd.DataFrame(lst_2017)[[1]].values)\n",
    "    second_cond_entropy_2018 = cond_entropy(pd.DataFrame(lst_2018)[2].values, pd.DataFrame(lst_2018)[[0, 1]].values)\n",
    "    first_cond_entropy_2018 = cond_entropy(pd.DataFrame(lst_2018)[2].values, pd.DataFrame(lst_2018)[[1]].values)\n",
    "    #diffs.append(first_cond_entropy_2017-second_cond_entropy_2017)\n",
    "    #stds.append(std_2017)\n",
    "    diffs.append(first_cond_entropy_2018-second_cond_entropy_2018)\n",
    "    stds.append(std_2018)\n",
    "    print(team, diffs[-1], std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "nsample = len(diffs)\n",
    "X = np.column_stack((np.repeat(1, nsample), diffs))\n",
    "\n",
    "model = sm.OLS(stds, X)\n",
    "results = model.fit()\n",
    "\n",
    "a, b = results.params\n",
    "\n",
    "plt.scatter(diffs, stds)\n",
    "plt.plot(diffs, a+b*np.array(diffs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
